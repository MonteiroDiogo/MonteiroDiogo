{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6VPMr2SwyT5",
        "outputId": "9c462eeb-a5a2-4c4a-f0f4-561d41633ea5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "!pip install pdfplumber\n",
        "\n",
        "import pdfplumber\n",
        "import nltk\n",
        "def NuvemdePalavras(cv, salvar = True):\n",
        "      '''\n",
        "      cv: caminho de um arquivo PDF\n",
        "      '''\n",
        "      arquivoPDF = pdfplumber.open(cv)\n",
        "      primeira_pagina = arquivoPDF.pages[0]\n",
        "\n",
        "      textoCRU = primeira_pagina.extract_text()\n",
        "\n",
        "      #Quebra o texto em palavras e coloca em um vetor\n",
        "      nltk.download('punkt')\n",
        "      lista_de_palavras = nltk.tokenize.word_tokenize(textoCRU)\n",
        "      lista_de_palavras\n",
        "\n",
        "      #deixar as palavras todas com letras minúsculas\n",
        "      lista_de_palavras = [palavra.lower() for palavra in lista_de_palavras]\n",
        "      lista_de_palavras\n",
        "\n",
        "\n",
        "      #lista de pontuação que queremos remover\n",
        "      pontuacao = ['(',')',';',':','[',']',',']\n",
        "\n",
        "\n",
        "      #lista de stop words (palavras que não tem valor para analise do programa)\n",
        "      nltk.download('stopwords')\n",
        "      stop_words = nltk.corpus.stopwords.words('portuguese')\n",
        "      stop_words\n",
        "\n",
        "\n",
        "      #lista de palavras sem stopword e pontuações\n",
        "      keywords = [palavra for palavra in lista_de_palavras if not palavra in stop_words and not palavra in pontuacao]\n",
        "      keywords\n",
        "\n",
        "\n",
        "\n",
        "      #concatenar palavras\n",
        "      textocv = \" \" .join (s for s in keywords)\n",
        "      textocv\n",
        "\n",
        "\n",
        "      #criar wordcloud\n",
        "\n",
        "      from wordcloud import WordCloud\n",
        "      \n",
        "      wordcloud = WordCloud(background_color = '#0f54c9',\n",
        "                                  max_font_size = 150,\n",
        "                                  width = 1280,\n",
        "                                  height = 720,\n",
        "                                  colormap= 'Blues').generate(textocv)\n",
        "#mostrar imagem do wordcloud\n",
        "#matplotlib ajuda na config dos graficos \n",
        "      import matplotlib.pyplot as plt\n",
        "      fig, ax = plt.subplots(figsize=(16,9))\n",
        "      ax.imshow(wordcloud)\n",
        "      ax.set_axis_off()\n",
        "      plt.imshow(wordcloud)\n",
        "      wordcloud.to_file(\"wordcloud.png\")\n",
        "      plt.show"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.5.28.tar.gz (45 kB)\n",
            "\u001b[K     |████████████████████████████████| 45 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting pdfminer.six==20200517\n",
            "  Downloading pdfminer.six-20200517-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 10.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=7.0.0 in /usr/local/lib/python3.7/dist-packages (from pdfplumber) (7.1.2)\n",
            "Collecting Wand\n",
            "  Downloading Wand-0.6.7-py2.py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 42.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (3.0.4)\n",
            "Collecting pycryptodome\n",
            "  Downloading pycryptodome-3.12.0-cp35-abi3-manylinux2010_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 39.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from pdfminer.six==20200517->pdfplumber) (2.4.0)\n",
            "Building wheels for collected packages: pdfplumber\n",
            "  Building wheel for pdfplumber (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pdfplumber: filename=pdfplumber-0.5.28-py3-none-any.whl size=32240 sha256=5e26bcd4ba8b086b4248c224666bad6153bd4ed873b62bdf99701df45fa8614a\n",
            "  Stored in directory: /root/.cache/pip/wheels/f2/b1/a0/c0a77b756d580f53b3806ae0e0b3ec945a8d05fca1d6e10cc1\n",
            "Successfully built pdfplumber\n",
            "Installing collected packages: pycryptodome, Wand, pdfminer.six, pdfplumber\n",
            "Successfully installed Wand-0.6.7 pdfminer.six-20200517 pdfplumber-0.5.28 pycryptodome-3.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "sck_m_gYasnK",
        "outputId": "629e4a4d-f4d9-4593-c96e-def25d9bb5f3"
      },
      "source": [
        "      arquivoPDF = pdfplumber.open('/content/CV - Juliana scudilio.pdf')\n",
        "      primeira_pagina = arquivoPDF.pages[0]\n",
        "\n",
        "      textoCRU = primeira_pagina.extract_text()\n",
        "\n",
        "      #Quebra o texto em palavras e coloca em um vetor\n",
        "      nltk.download('punkt')\n",
        "      lista_de_palavras = nltk.tokenize.word_tokenize(textoCRU)\n",
        "      lista_de_palavras\n",
        "\n",
        "      #deixar as palavras todas com letras minúsculas\n",
        "      lista_de_palavras = [palavra.lower() for palavra in lista_de_palavras]\n",
        "      lista_de_palavras\n",
        "\n",
        "\n",
        "      #lista de pontuação que queremos remover\n",
        "      pontuacao = ['(',')',';',':','[',']',',']\n",
        "\n",
        "\n",
        "      #lista de stop words (palavras que não tem valor para analise do programa)\n",
        "      nltk.download('stopwords')\n",
        "      stop_words = nltk.corpus.stopwords.words('portuguese')\n",
        "      stop_words\n",
        "\n",
        "\n",
        "      #lista de palavras sem stopword e pontuações\n",
        "      keywords = [palavra for palavra in lista_de_palavras if not palavra in stop_words and not palavra in pontuacao]\n",
        "      keywords\n",
        "\n",
        "\n",
        "\n",
        "      #concatenar palavras\n",
        "      textocv = \" \" .join (s for s in keywords)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f05dd86058a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0marquivoPDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpdfplumber\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/CV - Juliana scudilio.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprimeira_pagina\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marquivoPDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtextoCRU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimeira_pagina\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pdfplumber/pdf.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(cls, path_or_fp, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_or_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0minst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/CV - Juliana scudilio.pdf'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "vaxR22-AuYqC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova seção"
      ],
      "metadata": {
        "id": "moxXWQP7uZHm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftNjRzttzmff"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "vagas = pd.read_excel('vagas.xlsx', sheet_name = None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg3AMUgd0ZnH",
        "outputId": "1492b947-5713-4e3c-9cca-f5499feda4d0"
      },
      "source": [
        "n_vagas = len(vagas.keys())\n",
        "nome_vagas = list(vagas.keys())\n",
        "n_vagas"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jYxXLYM05OP",
        "outputId": "88eecb97-3be7-493a-fd55-47033de10a2b"
      },
      "source": [
        "nome_vagas\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ds_senior', 'ds_junior', 'eng_dados', 'marketing']"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cof-0wK308To"
      },
      "source": [
        "vagas = [vagas[nome_vagas[i]] for i in range(n_vagas)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vLs8tGpl34-X",
        "outputId": "40e28855-daf8-44b3-de5a-ffbe041a46e6"
      },
      "source": [
        "vaga1 = vagas[0]\n",
        "vaga1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>palavras-chave</th>\n",
              "      <th>pesos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>python</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>sql</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>linguagem r</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>machine learning</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>estatística</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>big data</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>negócio</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     palavras-chave  pesos\n",
              "0            python      1\n",
              "1               sql      1\n",
              "2       linguagem r      1\n",
              "3  machine learning      2\n",
              "4       estatística      2\n",
              "5          big data      2\n",
              "6           negócio      2"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "agWYYDff4BP2",
        "outputId": "82f60485-83c9-4fba-8b63-b48cb27c02a8"
      },
      "source": [
        "palavras_chaves = list(vaga1['palavras-chave'])\n",
        "palavras_chaves"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['python',\n",
              " 'sql',\n",
              " 'linguagem r',\n",
              " 'machine learning',\n",
              " 'estatística',\n",
              " 'big data',\n",
              " 'negócio']"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diEE5Nrt4ZLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4acbbdf6-4a1c-4ccb-a77c-8d420546f765"
      },
      "source": [
        "pesos = list(vaga1['pesos'])\n",
        "pesos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 1, 1, 2, 2, 2, 2]"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a3dV37UXUIC",
        "outputId": "b73c2ce9-4822-4fd1-b054-bd9976b4fb03"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "np.array(pesos)\n",
        "\n",
        "\n",
        "limite = 5\n",
        "pesos = list(vaga1['pesos'])\n",
        "palavras_chaves = list(vaga1['palavras-chave'])\n",
        "pmax = np.sum(np.array(pesos)* limite)\n",
        "print(pmax)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHfp3DqWXtKz",
        "outputId": "1f3f9850-e798-41b9-ead9-e62434cea2e4"
      },
      "source": [
        "###contando as palavras chaves no curriculo\n",
        "cont = [textocv.count(pc) for pc in 'palavras-chaves']\n",
        "cont"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[69, 252, 100, 252, 40, 156, 252, 195, 6, 99, 18, 252, 40, 212, 195]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4unVFFFZNo7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}